{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T02:47:53.442400Z",
     "start_time": "2019-04-22T02:47:51.661285Z"
    }
   },
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "from mxnet import autograd, gluon, init, nd\n",
    "from mxnet.gluon import data as gdata, loss as gloss, nn, rnn\n",
    "from sklearn import metrics\n",
    "import mxnet as mx\n",
    "from mxnet import autograd, gluon, init, nd\n",
    "from mxnet.gluon import data as gdata, loss as gloss, nn\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import sys\n",
    "sys.path.append('/data/CaoZhong/utils/')\n",
    "from my_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T02:24:49.426698Z",
     "start_time": "2019-04-22T02:24:47.573081Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user count: 1053\titem count: 63001\tcate count: 801\n",
      "train set len:  129888\n",
      "test set len:  2106\n"
     ]
    }
   ],
   "source": [
    "ctx = mx.gpu(0)\n",
    "train_batch_size = 64\n",
    "test_batch_size = 128\n",
    "model_name = 'din_basemodel_gluon'\n",
    "with open('/data/CaoZhong/data/dien/dataset_sub_gluon.pkl', 'rb') as f:\n",
    "    train_set = pickle.load(f)\n",
    "    test_set = pickle.load(f)\n",
    "    cate_list = pickle.load(f)\n",
    "    user_count, item_count, cate_count = pickle.load(f)\n",
    "random.shuffle(train_set)\n",
    "cate_list = nd.array(cate_list)\n",
    "print(\"user count: %d\\titem count: %d\\tcate count: %d\" % (user_count, item_count, cate_count))\n",
    "print(\"train set len: \",len(train_set))\n",
    "print('test set len: ', len(test_set))\n",
    "train_set = train_set[:10000]\n",
    "test_set = test_set[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T02:24:49.434451Z",
     "start_time": "2019-04-22T02:24:49.429053Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_data(data_set):    \n",
    "    all_user, all_hist,all_hist_neg, all_pre,  all_label = [],[],[],[],[]\n",
    "    for u, hist,hist_neg, pre, label in data_set:\n",
    "        all_user.append(u)\n",
    "        all_hist.append(hist)\n",
    "        all_hist_neg.append(hist_neg)\n",
    "        all_pre.append(pre)\n",
    "        all_label.append(label)\n",
    "    return all_user, all_hist, all_hist_neg, all_pre, all_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T02:24:49.451787Z",
     "start_time": "2019-04-22T02:24:49.436482Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def batchify(data):\n",
    "    max_len = max([len(h) for u, h, h_neg, p, l in data])\n",
    "    uid, hist,hist_neg, pre, label, sl= [], [], [], [], [],[]\n",
    "    for u, h, h_neg, p, l in data:\n",
    "        uid += [u]\n",
    "        sl += [len(h)]\n",
    "        pre += [p]\n",
    "        hist += [h + [0] * (max_len-len(h))]\n",
    "        hist_neg += [h_neg + [[0]*5]*(max_len - len(h))]\n",
    "        label += [l]\n",
    "    uid = nd.array(uid).reshape((-1))\n",
    "    hist_item = nd.array(hist)\n",
    "    hist_cate = cate_list[hist_item]\n",
    "    hist_item_neg = nd.array(hist_neg)\n",
    "    hist_cate_neg = cate_list[hist_item_neg]\n",
    "    item = nd.array(pre).reshape((-1))\n",
    "    cate = cate_list[item]\n",
    "    label = nd.array(label).reshape((-1))\n",
    "    seq_len = nd.array(sl).reshape((-1))\n",
    "    \n",
    "    return (uid, hist_item, hist_cate, hist_item_neg, hist_cate_neg, item, cate, label, seq_len, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T02:24:49.516022Z",
     "start_time": "2019-04-22T02:24:49.455335Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# 训练集\n",
    "all_user, all_hist, all_hist_neg, all_pre, all_label = get_data(train_set)\n",
    "dataset = gdata.ArrayDataset(all_user, all_hist, all_hist_neg, all_pre, all_label)\n",
    "# 测试集\n",
    "all_user, all_hist, all_hist_neg, all_pre, all_label = get_data(test_set)\n",
    "dataset_test = gdata.ArrayDataset(all_user, all_hist, all_hist_neg, all_pre, all_label)\n",
    "\n",
    "# 建立数据迭代器\n",
    "train_iter = gdata.DataLoader(dataset, train_batch_size, shuffle=True, batchify_fn=batchify)\n",
    "test_iter = gdata.DataLoader(dataset_test, test_batch_size, shuffle=True, batchify_fn=batchify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T02:24:49.714126Z",
     "start_time": "2019-04-22T02:24:49.519181Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uid shape:  (64,)\n",
      "hist shape:  (64, 281)\n",
      "hist_cate shape:  (64, 281)\n",
      "hist_item_neg shape:  (64, 281, 5)\n",
      "hist_cate_neg shape:  (64, 281, 5)\n",
      "pre shape:  (64,)\n",
      "pre_cate shape:  (64,)\n",
      "label shape:  (64,)\n",
      "sl shape:  (64,)\n",
      "281\n",
      "uid shape:  (128,)\n",
      "hist shape:  (128, 430)\n",
      "hist_cate shape:  (128, 430)\n",
      "hist_item_neg shape:  (128, 430, 5)\n",
      "hist_cate_neg shape:  (128, 430, 5)\n",
      "pre shape:  (128,)\n",
      "pre_cate shape:  (128,)\n",
      "label shape:  (128,)\n",
      "sl shape:  (128,)\n"
     ]
    }
   ],
   "source": [
    "for batch in train_iter:\n",
    "    for name, data in zip(['uid','hist','hist_cate','hist_item_neg','hist_cate_neg','pre','pre_cate','label','sl'], batch):\n",
    "        print(name, 'shape: ', data.shape)    \n",
    "    print(batch[-1])\n",
    "    break\n",
    "for batch in test_iter:\n",
    "    for name, data in zip(['uid','hist','hist_cate','hist_item_neg','hist_cate_neg','pre','pre_cate','label','sl'], batch):\n",
    "        print(name, 'shape: ', data.shape)        \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 建立模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T02:24:50.631349Z",
     "start_time": "2019-04-22T02:24:50.616186Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "function: 辅助函数损失\n",
    "Parameters: outpus - [B, T-1, 2E]\n",
    "            hist_item - [B, T-1, 2E]\n",
    "            noclk_hist_item - [B, T-1, 2E]\n",
    "            seq_len - [B,]\n",
    "Returns: \n",
    "\"\"\"\n",
    "def auxiliary_loss(net, h_states, hist_item, noclk_hist_item,seq_len):\n",
    "    print(h_states.shape, hist_item.shape, noclk_hist_item.shape,seq_len.shape)\n",
    "#     click_input = nd.concat(h_states, hist_item,dim=-1)\n",
    "#     noclick_input = nd.concat(h_states, noclk_hist_item, dim=-1)\n",
    "#     click_prop = net(click_input)\n",
    "#     click_prop = click_prop.reshape((-1, h_states.shape[1]))\n",
    "#     noclick_prop = net(noclick_input)\n",
    "#     noclick_prop = noclick_prop.reshape((-1, h_states.shape[1]))\n",
    "#     click_loss = - nd.log(click_prop)\n",
    "#     noclick_loss = -nd.log(1 - noclick_prop)\n",
    "#     print(click_loss.shape,noclick_loss.shape)\n",
    "#     loss_ = (click_loss + noclick_loss).mean(axis=1)\n",
    "    a = nd.concat(h_states, hist_item, noclk_hist_item)\n",
    "    b = net(a)\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T02:24:51.088233Z",
     "start_time": "2019-04-22T02:24:51.073694Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class Attention(nn.Block):\n",
    "    def __init__(self, attention_size, **kwargs):\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "        self.model = nn.Sequential()\n",
    "        self.model.add(nn.Dense(attention_size, activation='tanh', use_bias=False, flatten=False))\n",
    "        self.model.add(nn.Dense(1, use_bias=False, flatten=False))\n",
    "        \n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        query:    [B, H]\n",
    "        keys:     [T, B, H]\n",
    "        sl:       [B]\n",
    "    \"\"\"\n",
    "    def forward(self, keys, query,sl):\n",
    "        query = nd.broadcast_axis(query.expand_dims(0), axis=0, size=keys.shape[0])\n",
    "        item_history = nd.concat(keys, query, dim=2)\n",
    "        e = self.model(item_history)   # [T, B, 1]\n",
    "        e = nd.SequenceMask(e, sl.reshape((-1)), use_sequence_length=True, value=(-2 ** 32 + 1))\n",
    "        alpha = nd.softmax(e, axis=0)        # [T, B, 1]\n",
    "\n",
    "        return (alpha * keys).sum(axis=0)  # [T, B, 1] * [T, B, H]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T02:54:07.560672Z",
     "start_time": "2019-04-22T02:54:07.536311Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class Model(nn.Block):\n",
    "    def __init__(self, n_uid, n_mid, n_cat, embed_size, hidden_size, attention_size, ctx, **kwargs):\n",
    "        super(Model, self).__init__(**kwargs)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.attention_size = attention_size\n",
    "        self.embed_size = embed_size\n",
    "        self.uid_embedding = nn.Embedding(n_uid, 2*embed_size)\n",
    "        self.item_embedding = nn.Embedding(n_mid, embed_size)\n",
    "        self.cate_embedding = nn.Embedding(n_cat, embed_size)\n",
    "        self.rnn1 = rnn.GRU(hidden_size)\n",
    "        self.rnn2 = rnn.GRU(hidden_size)\n",
    "        self.attention_layer = Attention(attention_size)\n",
    "        \n",
    "#         self.aux_net = nn.Sequential()\n",
    "#         self.aux_net.add(nn.BatchNorm())\n",
    "#         self.aux_net.add(nn.Dense(100, activation='sigmoid', flatten=False))\n",
    "#         self.aux_net.add(nn.Dense(50, activation='sigmoid', flatten=False))\n",
    "#         self.aux_net.add(nn.Dense(1, activation='sigmoid', flatten=False))\n",
    "        \n",
    "        \n",
    "        self.mlp = nn.Sequential()\n",
    "        self.mlp.add(nn.BatchNorm())\n",
    "        self.mlp.add(nn.Dense(200, activation='relu'))\n",
    "        self.mlp.add(nn.Dense(80, activation='relu'))\n",
    "        self.mlp.add(nn.Dense(1, activation=None))\n",
    "    \n",
    "    def aux_loss(self, h_states, hist_item, noclk_hist_item,seq_len):\n",
    "#         seq_len = seq_len - 1 \n",
    "#         click_input = nd.concat(h_states, hist_item,dim=-1)\n",
    "#         noclick_input = nd.concat(h_states, noclk_hist_item, dim=-1)\n",
    "#         click_prop = self.aux_net(click_input)\n",
    "#         click_prop = click_prop.reshape((h_states.shape[0], h_states.shape[1]))\n",
    "#         noclick_prop = self.aux_net(noclick_input)\n",
    "#         noclick_prop = noclick_prop.reshape((h_states.shape[0], h_states.shape[1]))  # [B, T-1]\n",
    "#         click_loss = - nd.log(click_prop)\n",
    "#         noclick_loss = -nd.log(1 - noclick_prop)\n",
    "#         loss_ = (click_loss + noclick_loss).mean(axis=1)   # [B]\n",
    "        loss_ = self.aux_net(h_states).sum(axis=-1)\n",
    "        loss_ = loss_.mean(axis=-1)\n",
    "        return loss_\n",
    "    \n",
    "    def forward(self, uid, hist_item, hist_cate, noclk_hist_item, noclk_hist_cate,item, cate, seq_len):\n",
    "        uid_embed = self.uid_embedding(uid)\n",
    "        item_idx_embed = self.item_embedding(item)\n",
    "        cate_idx_embed = self.cate_embedding(cate)\n",
    "        item_embed = nd.concat(item_idx_embed, cate_idx_embed, dim=-1)\n",
    "        \n",
    "        hist_item_idx_embed = self.item_embedding(hist_item)\n",
    "        hist_cate_idx_embed = self.cate_embedding(hist_cate)\n",
    "        hist_item_embed = nd.concat(hist_item_idx_embed, hist_cate_idx_embed, dim=-1)  # [B, T, 2E]\n",
    "        hist_item_sum = nd.SequenceMask(hist_item_embed.swapaxes(0, 1), sequence_length=seq_len.reshape((-1)), use_sequence_length=True) # [T, B, H]\n",
    "        hist_item_sum = nd.sum(hist_item_sum, axis=0)  # [B, 2E]\n",
    "        \n",
    "        noclk_hist_item = self.item_embedding(noclk_hist_item)\n",
    "        noclk_hist_cate = self.item_embedding(noclk_hist_cate)\n",
    "        noclk_hist = nd.concat(noclk_hist_item, noclk_hist_cate, dim=-1)\n",
    "        noclk_hist_item_embed = noclk_hist[:,:,0,:]\n",
    "        noclk_hist_item_embed = noclk_hist_item_embed.reshape((-1, hist_item_embed.shape[1],hist_item_embed.shape[-1]))  # [B, T, 2E]\n",
    "\n",
    "        rnn_outputs = self.rnn1(hist_item_embed.swapaxes(0,1))  # [T, B, H]\n",
    "        \n",
    "        rnn_out2 = self.rnn2(rnn_outputs)\n",
    "        c = self.attention_layer(rnn_out2, item_embed, seq_len)\n",
    "        \n",
    "#         aux_loss = self.aux_loss(rnn_outputs.swapaxes(0,1)[:,:-1,:], hist_item_embed[:,1:,:], noclk_hist_item_embed[:,1:,:], seq_len)\n",
    "\n",
    "        inp = nd.concat(uid_embed, item_embed,hist_item_sum, item_embed*hist_item_sum, c, dim=1)\n",
    "        \n",
    "        \n",
    "        score = self.mlp(inp)\n",
    "        score = score.reshape((-1))\n",
    "        return score\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T02:54:07.992390Z",
     "start_time": "2019-04-22T02:54:07.968129Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def eval_auc(net,data_iter, ctx):\n",
    "    score = None\n",
    "    y = None\n",
    "    for batch in data_iter:\n",
    "        uid, hist_item, hist_cate, hist_item_neg, hist_cate_neg,item,cate, label, sl = [data.as_in_context(ctx) for data in batch[:-1]]\n",
    "        if score is None:\n",
    "            out = net(uid, hist_item, hist_cate,  hist_item_neg, hist_cate_neg,item, cate, sl)\n",
    "            score = nd.sigmoid(out)\n",
    "            y = label\n",
    "        else:\n",
    "            out = net(uid, hist_item, hist_cate,  hist_item_neg, hist_cate_neg,item, cate, sl)\n",
    "            score = nd.concat(score, nd.sigmoid(out), dim=0)\n",
    "            y = nd.concat(y, label, dim=0)\n",
    "    y = list(y.asnumpy())\n",
    "    score = list(score.asnumpy())\n",
    "    fpr,tpr,thresholds = metrics.roc_curve(y,score)\n",
    "    auc = metrics.auc(fpr,tpr)\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T03:03:23.458443Z",
     "start_time": "2019-04-22T03:03:23.433501Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def train(net, train_iter, test_iter,loss,train_batch_size,lr, num_epochs, ctx,log_dir,loss_name='loss',auc_name='auc'):\n",
    "    auc_list, loss_list = [], []\n",
    "    trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate':lr})\n",
    "    \n",
    "    global_step = 1\n",
    "    stime = time.time()\n",
    "    stime2 = time.time()\n",
    "    \n",
    "    loss_val, auc_val, time_val = 0.0, 0.0, 0.0\n",
    "    print('auc: %.4f' % (eval_auc(net,test_iter, ctx)))\n",
    "    epoch_bar = tqdm_notebook(range(1, num_epochs+1))\n",
    "    for epoch in epoch_bar:\n",
    "        l_sum = 0.0\n",
    "        bar = tqdm_notebook(train_iter)\n",
    "        for batch in bar:\n",
    "            uid, hist_item, hist_cate, hist_item_neg, hist_cate_neg,item,cate, label, sl = [data.as_in_context(ctx) for data in batch[:-1]]\n",
    "            with autograd.record():\n",
    "                pred = net(uid, hist_item, hist_cate,  hist_item_neg, hist_cate_neg,item, cate, sl)\n",
    "                l = loss(pred, label)\n",
    "#                 cross_loss = loss(pred, label)\n",
    "#                 print(aux_loss.shape,cross_loss.shape)\n",
    "#                 l = aux_loss + cross_loss\n",
    "            l.backward()\n",
    "            trainer.step(train_batch_size)\n",
    "            l_sum += l.mean().asscalar()            \n",
    "            if global_step % 200 ==0:\n",
    "                test_auc = eval_auc(net, test_iter, ctx)\n",
    "                loss_val = l_sum / 200\n",
    "                auc_val = test_auc\n",
    "                time_val = time.time()-stime2\n",
    "                tip = \"epoch %d, global step:%d, loss %.4f, test auc:%.4f, time:%.2f\" % (epoch,global_step, loss_val, auc_val, time_val )\n",
    "                bar.set_description_str(tip)\n",
    "                tip_info(tip,out=False)\n",
    "                loss_list.append(loss_val)\n",
    "                auc_list.append(auc_val)\n",
    "                l_sum = 0.0\n",
    "                stime2 = time.time()\n",
    "            global_step += 1\n",
    "        tip = 'epoch %d done, cost time:%.2f' % (epoch, time.time() - stime)\n",
    "        epoch_bar.set_description_str(tip)\n",
    "        tip_info(tip,out=False)\n",
    "\n",
    "    return loss_list, auc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T03:03:23.678705Z",
     "start_time": "2019-04-22T03:03:23.661043Z"
    }
   },
   "outputs": [],
   "source": [
    "loss = gloss.SigmoidBinaryCrossEntropyLoss()\n",
    "net = Model(user_count, item_count, cate_count, embed_size=64, hidden_size=128, attention_size=64, ctx=ctx)\n",
    "net.initialize(init=init.Xavier(),force_reinit=True, ctx=ctx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T03:03:24.480973Z",
     "start_time": "2019-04-22T03:03:24.241511Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score \n",
      "[ 0.08676144  0.04514597  0.04434888  0.05680565  0.02888979 -0.00232536\n",
      "  0.13141474 -0.08247334  0.38988367  0.31690297  0.11657902  0.19059235\n",
      "  0.05171814  0.02063869  0.19938983 -0.0685005  -0.10468584  0.2358349\n",
      "  0.14914741 -0.02646282 -0.04567137  0.5741412   0.2892901   0.20713036\n",
      "  0.01690616  0.05846286 -0.20863356  0.07982939  0.17581278 -0.00541545\n",
      "  0.09921096 -0.03071056  0.13370815  0.28222004  0.25328451 -0.04899491\n",
      "  0.16147175  0.08039463  0.28692159 -0.06616701  0.05925862  0.04246673\n",
      "  0.28147456 -0.03420046 -0.04096619  0.2921901   0.15486799 -0.20532647\n",
      "  0.17587635 -0.11961944 -0.10238911  0.27010387  0.54318792  0.1637041\n",
      "  0.10268231 -0.08182988  0.26392391  0.07880452 -0.07099348  0.0938931\n",
      "  0.04157631  0.13418497  0.14684059  0.05490597 -0.10827526  0.16860972\n",
      " -0.1135467   0.11178055  0.02927077  0.21986072 -0.08179523  0.12169919\n",
      " -0.15752591  0.26792324  0.08669492  0.04968623 -0.09148367  0.17287087\n",
      "  0.21661702 -0.12213755  0.08942667  0.18005775 -0.00636724  0.02173905\n",
      "  0.08917511  0.19911915  0.18001118 -0.15173076 -0.06737462  0.08853754\n",
      "  0.15674669  0.18544427  0.02327802 -0.06810223  0.18081446 -0.15864184\n",
      " -0.11459769  0.22124648 -0.05211747  0.23339051  0.44799188  0.03264433\n",
      "  0.02866285  0.01510442 -0.07871629  0.10124961  0.18806499  0.0055966\n",
      "  0.27621064  0.21097699 -0.10450976  0.08876267 -0.09935851 -0.03238359\n",
      "  0.22153576 -0.2769188   0.12263681 -0.06034559  0.13273384  0.21757397\n",
      "  0.08803096  0.17830215  0.18321179  0.11334861 -0.05903377  0.068697\n",
      "  0.1066841   0.18971765]\n",
      "<NDArray 128 @gpu(0)>\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(test_iter):\n",
    "    uid, hist_item, hist_cate, hist_item_neg, hist_cate_neg,item,cate, label, sl = [data.as_in_context(ctx) for data in batch[:-1]]\n",
    "    b = net(uid, hist_item, hist_cate, hist_item_neg, hist_cate_neg, item, cate, sl)   \n",
    "    print('score',b)\n",
    "#     print('loss',a)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-22T03:03:25.243Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc: 0.4977\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ddb5624b043432e80d98d84ce386494",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1064642083640acb41558abb03c0d20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=157), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28a0ccb97d3d4704b9a047b791db1bde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=157), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train(net, train_iter, test_iter, loss, train_batch_size, 0.1, 5, ctx, './logs', 'loss_dien','auc_dien')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T01:37:05.449608Z",
     "start_time": "2019-04-22T01:37:05.442348Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (uid_embedding): Embedding(1053 -> 64, float32)\n",
       "  (item_embedding): Embedding(63001 -> 64, float32)\n",
       "  (cate_embedding): Embedding(801 -> 64, float32)\n",
       "  (rnn1): GRU(128 -> 128.0, TNC)\n",
       "  (rnn2): GRU(None -> 128.0, TNC)\n",
       "  (attention_layer): Attention(\n",
       "    (model): Sequential(\n",
       "      (0): Dense(256 -> 64, Activation(tanh))\n",
       "      (1): Dense(64 -> 1, linear)\n",
       "    )\n",
       "  )\n",
       "  (mlp): Sequential(\n",
       "    (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=576)\n",
       "    (1): Dense(576 -> 200, Activation(relu))\n",
       "    (2): Dense(200 -> 80, Activation(relu))\n",
       "    (3): Dense(80 -> 1, linear)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
