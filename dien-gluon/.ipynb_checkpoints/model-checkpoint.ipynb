{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T02:47:53.442400Z",
     "start_time": "2019-04-22T02:47:51.661285Z"
    }
   },
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "from mxnet import autograd, gluon, init, nd\n",
    "from mxnet.gluon import data as gdata, loss as gloss, nn, rnn\n",
    "from sklearn import metrics\n",
    "import mxnet as mx\n",
    "from mxnet import autograd, gluon, init, nd\n",
    "from mxnet.gluon import data as gdata, loss as gloss, nn\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import sys\n",
    "sys.path.append('/data/CaoZhong/utils/')\n",
    "from my_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T02:24:49.426698Z",
     "start_time": "2019-04-22T02:24:47.573081Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user count: 1053\titem count: 63001\tcate count: 801\n",
      "train set len:  129888\n",
      "test set len:  2106\n"
     ]
    }
   ],
   "source": [
    "ctx = mx.gpu(0)\n",
    "train_batch_size = 64\n",
    "test_batch_size = 128\n",
    "model_name = 'din_basemodel_gluon'\n",
    "with open('/data/CaoZhong/data/dien/dataset_sub_gluon.pkl', 'rb') as f:\n",
    "    train_set = pickle.load(f)\n",
    "    test_set = pickle.load(f)\n",
    "    cate_list = pickle.load(f)\n",
    "    user_count, item_count, cate_count = pickle.load(f)\n",
    "random.shuffle(train_set)\n",
    "cate_list = nd.array(cate_list)\n",
    "print(\"user count: %d\\titem count: %d\\tcate count: %d\" % (user_count, item_count, cate_count))\n",
    "print(\"train set len: \",len(train_set))\n",
    "print('test set len: ', len(test_set))\n",
    "train_set = train_set[:10000]\n",
    "test_set = test_set[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T02:24:49.434451Z",
     "start_time": "2019-04-22T02:24:49.429053Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_data(data_set):    \n",
    "    all_user, all_hist,all_hist_neg, all_pre,  all_label = [],[],[],[],[]\n",
    "    for u, hist,hist_neg, pre, label in data_set:\n",
    "        all_user.append(u)\n",
    "        all_hist.append(hist)\n",
    "        all_hist_neg.append(hist_neg)\n",
    "        all_pre.append(pre)\n",
    "        all_label.append(label)\n",
    "    return all_user, all_hist, all_hist_neg, all_pre, all_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T02:24:49.451787Z",
     "start_time": "2019-04-22T02:24:49.436482Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def batchify(data):\n",
    "    max_len = max([len(h) for u, h, h_neg, p, l in data])\n",
    "    uid, hist,hist_neg, pre, label, sl= [], [], [], [], [],[]\n",
    "    for u, h, h_neg, p, l in data:\n",
    "        uid += [u]\n",
    "        sl += [len(h)]\n",
    "        pre += [p]\n",
    "        hist += [h + [0] * (max_len-len(h))]\n",
    "        hist_neg += [h_neg + [[0]*5]*(max_len - len(h))]\n",
    "        label += [l]\n",
    "    uid = nd.array(uid).reshape((-1))\n",
    "    hist_item = nd.array(hist)\n",
    "    hist_cate = cate_list[hist_item]\n",
    "    hist_item_neg = nd.array(hist_neg)\n",
    "    hist_cate_neg = cate_list[hist_item_neg]\n",
    "    item = nd.array(pre).reshape((-1))\n",
    "    cate = cate_list[item]\n",
    "    label = nd.array(label).reshape((-1))\n",
    "    seq_len = nd.array(sl).reshape((-1))\n",
    "    \n",
    "    return (uid, hist_item, hist_cate, hist_item_neg, hist_cate_neg, item, cate, label, seq_len, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T02:24:49.516022Z",
     "start_time": "2019-04-22T02:24:49.455335Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# 训练集\n",
    "all_user, all_hist, all_hist_neg, all_pre, all_label = get_data(train_set)\n",
    "dataset = gdata.ArrayDataset(all_user, all_hist, all_hist_neg, all_pre, all_label)\n",
    "# 测试集\n",
    "all_user, all_hist, all_hist_neg, all_pre, all_label = get_data(test_set)\n",
    "dataset_test = gdata.ArrayDataset(all_user, all_hist, all_hist_neg, all_pre, all_label)\n",
    "\n",
    "# 建立数据迭代器\n",
    "train_iter = gdata.DataLoader(dataset, train_batch_size, shuffle=True, batchify_fn=batchify)\n",
    "test_iter = gdata.DataLoader(dataset_test, test_batch_size, shuffle=True, batchify_fn=batchify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T02:24:49.714126Z",
     "start_time": "2019-04-22T02:24:49.519181Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uid shape:  (64,)\n",
      "hist shape:  (64, 281)\n",
      "hist_cate shape:  (64, 281)\n",
      "hist_item_neg shape:  (64, 281, 5)\n",
      "hist_cate_neg shape:  (64, 281, 5)\n",
      "pre shape:  (64,)\n",
      "pre_cate shape:  (64,)\n",
      "label shape:  (64,)\n",
      "sl shape:  (64,)\n",
      "281\n",
      "uid shape:  (128,)\n",
      "hist shape:  (128, 430)\n",
      "hist_cate shape:  (128, 430)\n",
      "hist_item_neg shape:  (128, 430, 5)\n",
      "hist_cate_neg shape:  (128, 430, 5)\n",
      "pre shape:  (128,)\n",
      "pre_cate shape:  (128,)\n",
      "label shape:  (128,)\n",
      "sl shape:  (128,)\n"
     ]
    }
   ],
   "source": [
    "for batch in train_iter:\n",
    "    for name, data in zip(['uid','hist','hist_cate','hist_item_neg','hist_cate_neg','pre','pre_cate','label','sl'], batch):\n",
    "        print(name, 'shape: ', data.shape)    \n",
    "    print(batch[-1])\n",
    "    break\n",
    "for batch in test_iter:\n",
    "    for name, data in zip(['uid','hist','hist_cate','hist_item_neg','hist_cate_neg','pre','pre_cate','label','sl'], batch):\n",
    "        print(name, 'shape: ', data.shape)        \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 建立模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T02:24:50.631349Z",
     "start_time": "2019-04-22T02:24:50.616186Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "function: 辅助函数损失\n",
    "Parameters: outpus - [B, T-1, 2E]\n",
    "            hist_item - [B, T-1, 2E]\n",
    "            noclk_hist_item - [B, T-1, 2E]\n",
    "            seq_len - [B,]\n",
    "Returns: \n",
    "\"\"\"\n",
    "def auxiliary_loss(net, h_states, hist_item, noclk_hist_item,seq_len):\n",
    "    print(h_states.shape, hist_item.shape, noclk_hist_item.shape,seq_len.shape)\n",
    "#     click_input = nd.concat(h_states, hist_item,dim=-1)\n",
    "#     noclick_input = nd.concat(h_states, noclk_hist_item, dim=-1)\n",
    "#     click_prop = net(click_input)\n",
    "#     click_prop = click_prop.reshape((-1, h_states.shape[1]))\n",
    "#     noclick_prop = net(noclick_input)\n",
    "#     noclick_prop = noclick_prop.reshape((-1, h_states.shape[1]))\n",
    "#     click_loss = - nd.log(click_prop)\n",
    "#     noclick_loss = -nd.log(1 - noclick_prop)\n",
    "#     print(click_loss.shape,noclick_loss.shape)\n",
    "#     loss_ = (click_loss + noclick_loss).mean(axis=1)\n",
    "    a = nd.concat(h_states, hist_item, noclk_hist_item)\n",
    "    b = net(a)\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T02:24:51.088233Z",
     "start_time": "2019-04-22T02:24:51.073694Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class Attention(nn.Block):\n",
    "    def __init__(self, attention_size, **kwargs):\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "        self.model = nn.Sequential()\n",
    "        self.model.add(nn.Dense(attention_size, activation='tanh', use_bias=False, flatten=False))\n",
    "        self.model.add(nn.Dense(1, use_bias=False, flatten=False))\n",
    "        \n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        query:    [B, H]\n",
    "        keys:     [T, B, H]\n",
    "        sl:       [B]\n",
    "    \"\"\"\n",
    "    def forward(self, keys, query,sl):\n",
    "        query = nd.broadcast_axis(query.expand_dims(0), axis=0, size=keys.shape[0])\n",
    "        item_history = nd.concat(keys, query, dim=2)\n",
    "        e = self.model(item_history)   # [T, B, 1]\n",
    "        e = nd.SequenceMask(e, sl.reshape((-1)), use_sequence_length=True, value=(-2 ** 32 + 1))\n",
    "        alpha = nd.softmax(e, axis=0)        # [T, B, 1]\n",
    "\n",
    "        return (alpha * keys).sum(axis=0)  # [T, B, 1] * [T, B, H]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T02:40:18.857566Z",
     "start_time": "2019-04-22T02:40:18.819229Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class Model(nn.Block):\n",
    "    def __init__(self, n_uid, n_mid, n_cat, embed_size, hidden_size, attention_size, ctx, **kwargs):\n",
    "        super(Model, self).__init__(**kwargs)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.attention_size = attention_size\n",
    "        self.embed_size = embed_size\n",
    "        self.uid_embedding = nn.Embedding(n_uid, embed_size)\n",
    "        self.item_embedding = nn.Embedding(n_mid, embed_size)\n",
    "        self.cate_embedding = nn.Embedding(n_cat, embed_size)\n",
    "        self.rnn1 = rnn.GRU(hidden_size)\n",
    "        self.rnn2 = rnn.GRU(hidden_size)\n",
    "        self.attention_layer = Attention(attention_size)\n",
    "        \n",
    "        self.aux_net = nn.Sequential()\n",
    "        self.aux_net.add(nn.BatchNorm())\n",
    "        self.aux_net.add(nn.Dense(100, activation='sigmoid', flatten=False))\n",
    "        self.aux_net.add(nn.Dense(50, activation='sigmoid', flatten=False))\n",
    "        self.aux_net.add(nn.Dense(1, activation='sigmoid', flatten=False))\n",
    "        \n",
    "        \n",
    "        self.mlp = nn.Sequential()\n",
    "        self.mlp.add(nn.BatchNorm())\n",
    "        self.mlp.add(nn.Dense(200, activation='relu'))\n",
    "        self.mlp.add(nn.Dense(80, activation='relu'))\n",
    "        self.mlp.add(nn.Dense(1, activation=None))\n",
    "    \n",
    "    def aux_loss(self, h_states, hist_item, noclk_hist_item,seq_len):\n",
    "#         seq_len = seq_len - 1 \n",
    "#         click_input = nd.concat(h_states, hist_item,dim=-1)\n",
    "#         noclick_input = nd.concat(h_states, noclk_hist_item, dim=-1)\n",
    "#         click_prop = self.aux_net(click_input)\n",
    "#         click_prop = click_prop.reshape((h_states.shape[0], h_states.shape[1]))\n",
    "#         noclick_prop = self.aux_net(noclick_input)\n",
    "#         noclick_prop = noclick_prop.reshape((h_states.shape[0], h_states.shape[1]))  # [B, T-1]\n",
    "#         click_loss = - nd.log(click_prop)\n",
    "#         noclick_loss = -nd.log(1 - noclick_prop)\n",
    "#         loss_ = (click_loss + noclick_loss).mean(axis=1)   # [B]\n",
    "        loss_ = self.aux_net(h_states).sum(axis=-1)\n",
    "        loss_ = loss_.mean(axis=-1)\n",
    "        return loss_\n",
    "    \n",
    "    def forward(self, uid, hist_item, hist_cate, noclk_hist_item, noclk_hist_cate,item, cate, seq_len):\n",
    "        uid_embed = self.uid_embedding(uid)\n",
    "        item_idx_embed = self.item_embedding(item)\n",
    "        cate_idx_embed = self.cate_embedding(cate)\n",
    "        item_embed = nd.concat(item_idx_embed, cate_idx_embed, dim=-1)\n",
    "        \n",
    "        hist_item_idx_embed = self.item_embedding(hist_item)\n",
    "        hist_cate_idx_embed = self.cate_embedding(hist_cate)\n",
    "        hist_item_embed = nd.concat(hist_item_idx_embed, hist_cate_idx_embed, dim=-1)  # [B, T, 2E]\n",
    "        hist_item_sum = nd.SequenceMask(hist_item_embed.swapaxes(0, 1), sequence_length=seq_len.reshape((-1)), use_sequence_length=True) # [T, B, H]\n",
    "        hist_item_sum = nd.sum(hist_item_sum, axis=0)  # [B, 2E]\n",
    "        \n",
    "        noclk_hist_item = self.item_embedding(noclk_hist_item)\n",
    "        noclk_hist_cate = self.item_embedding(noclk_hist_cate)\n",
    "        noclk_hist = nd.concat(noclk_hist_item, noclk_hist_cate, dim=-1)\n",
    "        noclk_hist_item_embed = noclk_hist[:,:,0,:]\n",
    "        noclk_hist_item_embed = noclk_hist_item_embed.reshape((-1, hist_item_embed.shape[1],hist_item_embed.shape[-1]))  # [B, T, 2E]\n",
    "\n",
    "        rnn_outputs = self.rnn1(hist_item_embed.swapaxes(0,1))  # [T, B, H]\n",
    "        \n",
    "        rnn_out2 = self.rnn2(rnn_outputs)\n",
    "        c = self.attention_layer(rnn_out2, item_embed, seq_len)\n",
    "        \n",
    "#         aux_loss = self.aux_loss(rnn_outputs.swapaxes(0,1)[:,:-1,:], hist_item_embed[:,1:,:], noclk_hist_item_embed[:,1:,:], seq_len)\n",
    "\n",
    "        inp = nd.concat(uid_embed, item_embed,hist_item_sum, item_embed*hist_item_sum, c, dim=1)\n",
    "        \n",
    "        \n",
    "        score = self.mlp(inp)\n",
    "        score = score.reshape((-1))\n",
    "        return aux_loss, score\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T02:40:19.269277Z",
     "start_time": "2019-04-22T02:40:19.254298Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def eval_auc(net,data_iter, ctx):\n",
    "    score = None\n",
    "    y = None\n",
    "    for batch in data_iter:\n",
    "        uid, hist_item, hist_cate, hist_item_neg, hist_cate_neg,item,cate, label, sl = [data.as_in_context(ctx) for data in batch[:-1]]\n",
    "        if score is None:\n",
    "            _, out = net(uid, hist_item, hist_cate,  hist_item_neg, hist_cate_neg,item, cate, sl)\n",
    "            score = nd.sigmoid(out)\n",
    "            y = label\n",
    "        else:\n",
    "            _,out = net(uid, hist_item, hist_cate,  hist_item_neg, hist_cate_neg,item, cate, sl)\n",
    "            score = nd.concat(score, nd.sigmoid(out), dim=0)\n",
    "            y = nd.concat(y, label, dim=0)\n",
    "    y = list(y.asnumpy())\n",
    "    score = list(score.asnumpy())\n",
    "    fpr,tpr,thresholds = metrics.roc_curve(y,score)\n",
    "    auc = metrics.auc(fpr,tpr)\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T02:40:19.489345Z",
     "start_time": "2019-04-22T02:40:19.462141Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def train(net, train_iter, test_iter,loss,train_batch_size,lr, num_epochs, ctx,log_dir,loss_name='loss',auc_name='auc'):\n",
    "    auc_list, loss_list = [], []\n",
    "    trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate':lr})\n",
    "    \n",
    "    global_step = 1\n",
    "    stime = time.time()\n",
    "    stime2 = time.time()\n",
    "    \n",
    "    loss_val, auc_val, time_val = 0.0, 0.0, 0.0\n",
    "    print('auc: %.4f' % (eval_auc(net,test_iter, ctx)))\n",
    "    epoch_bar = tqdm_notebook(range(1, num_epochs+1))\n",
    "    for epoch in epoch_bar:\n",
    "        l_sum = 0.0\n",
    "        bar = tqdm_notebook(train_iter)\n",
    "        for batch in bar:\n",
    "            uid, hist_item, hist_cate, hist_item_neg, hist_cate_neg,item,cate, label, sl = [data.as_in_context(ctx) for data in batch[:-1]]\n",
    "            with autograd.record():\n",
    "                aux_loss, pred = net(uid, hist_item, hist_cate,  hist_item_neg, hist_cate_neg,item, cate, sl)\n",
    "#                 l = loss(pred, label)\n",
    "                cross_loss = loss(pred, label)\n",
    "                print(aux_loss.shape,cross_loss.shape)\n",
    "                l = aux_loss + cross_loss\n",
    "            l.backward()\n",
    "            trainer.step(train_batch_size)\n",
    "            l_sum += l.mean().asscalar()            \n",
    "            if global_step % 1000 ==0:\n",
    "                test_auc = eval_auc(net, test_iter, ctx)\n",
    "                loss_val = l_sum / 1000\n",
    "                auc_val = test_auc\n",
    "                time_val = time.time()-stime2\n",
    "                tip = \"epoch %d, global step:%d, loss %.4f, test auc:%.4f, time:%.2f\" % (epoch,global_step, loss_val, auc_val, time_val )\n",
    "                bar.set_description_str(tip)\n",
    "                tip_info(tip,out=False)\n",
    "                loss_list.append(loss_val)\n",
    "                auc_list.append(auc_val)\n",
    "                l_sum = 0.0\n",
    "                stime2 = time.time()\n",
    "            global_step += 1\n",
    "        tip = 'epoch %d done, cost time:%.2f' % (epoch, time.time() - stime)\n",
    "        epoch_bar.set_description_str(tip)\n",
    "        tip_info(tip,out=False)\n",
    "\n",
    "    return loss_list, auc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T02:40:19.984591Z",
     "start_time": "2019-04-22T02:40:19.955274Z"
    }
   },
   "outputs": [],
   "source": [
    "loss = gloss.SigmoidBinaryCrossEntropyLoss()\n",
    "net = Model(user_count, item_count, cate_count, embed_size=64, hidden_size=128, attention_size=64, ctx=ctx)\n",
    "net.initialize(init=init.Xavier(),force_reinit=True, ctx=ctx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T02:40:20.629466Z",
     "start_time": "2019-04-22T02:40:20.625432Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# for i, batch in enumerate(test_iter):\n",
    "#     uid, hist_item, hist_cate, hist_item_neg, hist_cate_neg,item,cate, label, sl = [data.as_in_context(ctx) for data in batch[:-1]]\n",
    "#     b = net(uid, hist_item, hist_cate, hist_item_neg, hist_cate_neg, item, cate, sl)   \n",
    "#     print('score',b)\n",
    "# #     print('loss',a)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T02:40:21.936612Z",
     "start_time": "2019-04-22T02:40:21.132698Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 332, 128)\n",
      "(128, 210, 128)\n",
      "(128, 240, 128)\n",
      "(128, 249, 128)\n",
      "(128, 280, 128)\n",
      "(128, 430, 128)\n",
      "(128, 260, 128)\n",
      "(104, 243, 128)\n"
     ]
    },
    {
     "ename": "MXNetError",
     "evalue": "[22:40:21] include/mxnet/././tensor_blob.h:257: Check failed: this->shape_.Size() == shape.Size() (332 vs. 210) TBlob.get_with_shape: new and old shape do not match total elements\n\nStack trace returned 10 entries:\n[bt] (0) /data/CaoZhong/anaconda3/envs/py36/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x31f81a) [0x7fa177c3781a]\n[bt] (1) /data/CaoZhong/anaconda3/envs/py36/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x31fe41) [0x7fa177c37e41]\n[bt] (2) /data/CaoZhong/anaconda3/envs/py36/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x2a7cdd4) [0x7fa17a394dd4]\n[bt] (3) /data/CaoZhong/anaconda3/envs/py36/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x2b68766) [0x7fa17a480766]\n[bt] (4) /data/CaoZhong/anaconda3/envs/py36/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x2b6d127) [0x7fa17a485127]\n[bt] (5) /data/CaoZhong/anaconda3/envs/py36/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x25090b0) [0x7fa179e210b0]\n[bt] (6) /data/CaoZhong/anaconda3/envs/py36/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x2480ff9) [0x7fa179d98ff9]\n[bt] (7) /data/CaoZhong/anaconda3/envs/py36/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x248abf4) [0x7fa179da2bf4]\n[bt] (8) /data/CaoZhong/anaconda3/envs/py36/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x248ea93) [0x7fa179da6a93]\n[bt] (9) /data/CaoZhong/anaconda3/envs/py36/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x248ece6) [0x7fa179da6ce6]\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMXNetError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-6466ae6aafbb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'./logs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'loss_dien'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'auc_dien'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-44-78201577b7a5>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, train_iter, test_iter, loss, train_batch_size, lr, num_epochs, ctx, log_dir, loss_name, auc_name)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mloss_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauc_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'auc: %.4f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0meval_auc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mepoch_bar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_bar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-43-2dde5d4a7415>\u001b[0m in \u001b[0;36meval_auc\u001b[0;34m(net, data_iter, ctx)\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mthresholds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mauc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/mxnet/ndarray/ndarray.py\u001b[0m in \u001b[0;36masnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1874\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1875\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1876\u001b[0;31m             ctypes.c_size_t(data.size)))\n\u001b[0m\u001b[1;32m   1877\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/mxnet/base.py\u001b[0m in \u001b[0;36mcheck_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    147\u001b[0m     \"\"\"\n\u001b[1;32m    148\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMXNetError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMXGetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMXNetError\u001b[0m: [22:40:21] include/mxnet/././tensor_blob.h:257: Check failed: this->shape_.Size() == shape.Size() (332 vs. 210) TBlob.get_with_shape: new and old shape do not match total elements\n\nStack trace returned 10 entries:\n[bt] (0) /data/CaoZhong/anaconda3/envs/py36/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x31f81a) [0x7fa177c3781a]\n[bt] (1) /data/CaoZhong/anaconda3/envs/py36/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x31fe41) [0x7fa177c37e41]\n[bt] (2) /data/CaoZhong/anaconda3/envs/py36/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x2a7cdd4) [0x7fa17a394dd4]\n[bt] (3) /data/CaoZhong/anaconda3/envs/py36/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x2b68766) [0x7fa17a480766]\n[bt] (4) /data/CaoZhong/anaconda3/envs/py36/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x2b6d127) [0x7fa17a485127]\n[bt] (5) /data/CaoZhong/anaconda3/envs/py36/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x25090b0) [0x7fa179e210b0]\n[bt] (6) /data/CaoZhong/anaconda3/envs/py36/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x2480ff9) [0x7fa179d98ff9]\n[bt] (7) /data/CaoZhong/anaconda3/envs/py36/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x248abf4) [0x7fa179da2bf4]\n[bt] (8) /data/CaoZhong/anaconda3/envs/py36/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x248ea93) [0x7fa179da6a93]\n[bt] (9) /data/CaoZhong/anaconda3/envs/py36/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x248ece6) [0x7fa179da6ce6]\n\n"
     ]
    }
   ],
   "source": [
    "train(net, train_iter, test_iter, loss, train_batch_size, 0.1, 5, ctx, './logs', 'loss_dien','auc_dien')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-22T01:37:05.449608Z",
     "start_time": "2019-04-22T01:37:05.442348Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (uid_embedding): Embedding(1053 -> 64, float32)\n",
       "  (item_embedding): Embedding(63001 -> 64, float32)\n",
       "  (cate_embedding): Embedding(801 -> 64, float32)\n",
       "  (rnn1): GRU(128 -> 128.0, TNC)\n",
       "  (rnn2): GRU(None -> 128.0, TNC)\n",
       "  (attention_layer): Attention(\n",
       "    (model): Sequential(\n",
       "      (0): Dense(256 -> 64, Activation(tanh))\n",
       "      (1): Dense(64 -> 1, linear)\n",
       "    )\n",
       "  )\n",
       "  (mlp): Sequential(\n",
       "    (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=576)\n",
       "    (1): Dense(576 -> 200, Activation(relu))\n",
       "    (2): Dense(200 -> 80, Activation(relu))\n",
       "    (3): Dense(80 -> 1, linear)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
