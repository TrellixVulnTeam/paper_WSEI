{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T06:54:43.007174Z",
     "start_time": "2019-04-24T06:54:40.588070Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import mxnet as mx\n",
    "from mxnet import autograd, gluon, init, nd\n",
    "from mxnet.gluon import data as gdata, loss as gloss, nn\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "import sys\n",
    "sys.path.append('/data/CaoZhong/utils/')\n",
    "from my_utils import *\n",
    "from tqdm import tqdm_notebook,tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T06:54:43.014972Z",
     "start_time": "2019-04-24T06:54:43.010988Z"
    }
   },
   "outputs": [],
   "source": [
    "ctx = mx.gpu(5)\n",
    "train_batch_size = 64\n",
    "test_batch_size = 512\n",
    "model_name = 'rnn_att_din'\n",
    "data_path = '/data/CaoZhong/data/din/dataset_sub_gluon.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T06:54:50.664733Z",
     "start_time": "2019-04-24T06:54:49.536914Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user count: 1053\titem count: 63001\tcate count: 801\n",
      "train set len:  129888\n",
      "test set len:  2106\n"
     ]
    }
   ],
   "source": [
    "data_iter = DinDataIter(data_path, train_batch_size, test_batch_size)\n",
    "user_count, item_count, cate_count = data_iter.get_count()\n",
    "train_iter, test_iter = data_iter.get_data_iter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T06:55:19.117735Z",
     "start_time": "2019-04-24T06:55:18.788943Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uid shape:  (64,) cpu(0)\n",
      "hist shape:  (64, 262) cpu(0)\n",
      "hist_cate shape:  (64, 262) cpu(0)\n",
      "pre shape:  (64,) cpu(0)\n",
      "cate shape:  (64,) cpu(0)\n",
      "label shape:  (64,) cpu(0)\n",
      "sl shape:  (64,) cpu(0)\n",
      "uid shape:  (512,)\n",
      "hist shape:  (512, 366)\n",
      "hist_cate shape:  (512, 366)\n",
      "pre shape:  (512,)\n",
      "cate shape:  (512,)\n",
      "label shape:  (512,)\n",
      "sl shape:  (512,)\n"
     ]
    }
   ],
   "source": [
    "for batch in train_iter:\n",
    "    for name, data in zip(['uid','hist','hist_cate','pre','cate','label','sl'], batch):\n",
    "        print(name, 'shape: ', data.shape, data.context)        \n",
    "    break\n",
    "for batch in test_iter:\n",
    "    for name, data in zip(['uid','hist','hist_cate','pre','cate','label','sl'], batch):\n",
    "        print(name, 'shape: ', data.shape)        \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立模型——RNN模型\n",
    "- 使用注意力机制，根据当前输入动态获得背景向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T06:57:26.252495Z",
     "start_time": "2019-04-24T06:57:26.227255Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class Model(nn.Block):\n",
    "    def __init__(self,item_count, cate_count, embed_size, num_hiddens, attention_size, ctx, **kwargs):\n",
    "        super(Model, self).__init__(**kwargs)\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.item_embedding = nn.Embedding(item_count, embed_size)\n",
    "        self.cate_embedding = nn.Embedding(cate_count, embed_size)\n",
    "        self.batch_normal_layer = nn.BatchNorm()\n",
    "        self.dense_layer = nn.Dense(num_hiddens)\n",
    "        self.encoder = rnn.LSTM(2*num_hiddens)\n",
    "        self.attention_layer = Attention(attention_size)\n",
    "       \n",
    "        self.mlp = nn.Sequential()\n",
    "        self.mlp.add(nn.BatchNorm())\n",
    "        self.mlp.add(nn.Dense(80, activation='sigmoid'))\n",
    "        self.mlp.add(nn.Dense(40, activation='sigmoid'))\n",
    "        self.mlp.add(nn.Dense(1, activation=None))       \n",
    "    \n",
    "    def forward(self, item, cate, hist_item, hist_cate, seq_len):\n",
    "        item = item.reshape((-1))\n",
    "        seq_len = seq_len.reshape((-1))\n",
    "        item_idx_emb = self.item_embedding(item)\n",
    "        cate_idx_emb = self.cate_embedding(cate)\n",
    "        item_emb = nd.concat(item_idx_emb, cate_idx_emb, dim=1)\n",
    "        \n",
    "        hist_item_idx_emb = self.item_embedding(hist_item)\n",
    "        hist_cate_idx_emb = self.cate_embedding(hist_cate)\n",
    "        hist_emb = nd.concat(hist_item_idx_emb, hist_cate_idx_emb, dim = -1)\n",
    "        hist_emb = dynamic_rnn(self.encoder, hist_emb.swapaxes(0,1))  # [T, B, H]\n",
    "        \n",
    "        c = self.attention_layer(hist_emb, item_emb, seq_len)\n",
    "        \n",
    "        h_emb = self.batch_normal_layer(c)\n",
    "        h_emb = self.dense_layer(h_emb)\n",
    "        user_emb = h_emb\n",
    "        din = nd.concat(user_emb, item_emb, dim=-1)\n",
    "        score = self.mlp(din)\n",
    "        return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = gloss.SigmoidBinaryCrossEntropyLoss()\n",
    "net = Model(item_count, cate_count, embed_size=64, num_hiddens=128, ctx=ctx)\n",
    "net.initialize(init=init.Xavier(),force_reinit=True, ctx=ctx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
